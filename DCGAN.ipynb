{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "879b48c9-c9c2-450b-b5e5-c9101fad8adf",
   "metadata": {},
   "source": [
    "## Install python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d365bef-0cc4-4226-92d1-042741533dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
      "Requirement already satisfied: pydot in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
      "Requirement already satisfied: tensorflow[and-cuda] in /usr/local/lib/python3.11/dist-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (70.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow[and-cuda]) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (2.17.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (0.37.1)\n",
      "Collecting nvidia-cublas-cu12==12.3.4.1 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cublas_cu12-12.3.4.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.3.101 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-nvcc-cu12==12.3.107 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvcc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.3.107 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.3.101 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.7.29 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.12.1 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cufft_cu12-11.0.12.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.4.107 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_curand_cu12-10.3.4.107-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.5.4.101 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusolver_cu12-11.5.4.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.2.0.103 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusparse_cu12-12.2.0.103-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.3.101 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.43.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow[and-cuda]) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow[and-cuda]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow[and-cuda]) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow[and-cuda]) (2.1.5)\n",
      "Downloading nvidia_cublas_cu12-12.3.4.1-py3-none-manylinux1_x86_64.whl (412.6 MB)\n",
      "\u001b[2K   \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/412.6 MB\u001b[0m \u001b[31m79.6 kB/s\u001b[0m eta \u001b[36m1:25:02\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install numpy keras matplotlib pydot python-dotenv tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a726ec91-6b6b-49d5-8824-a8abc524cf2d",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192e653d-b11b-41c7-a6a7-4ee97a5aa6d7",
   "metadata": {},
   "source": [
    "## Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52c52da-8b8e-4579-a4a5-d52bd6b98b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e98afc-a04d-456f-8c8d-d9d01d8226f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e494bb3-0b87-499b-adee-b0babe696ef2",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d10c74c-e5fe-4e8a-bdde-5db9d5f2d741",
   "metadata": {},
   "source": [
    "## Install graphviz (for linux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531981a4-8682-4ad7-b3e0-8f021f16cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SUDO = os.getenv('USE_SUDO')\n",
    "\n",
    "bash_command = \"apt-get install graphviz -y\"\n",
    "\n",
    "if USE_SUDO:\n",
    "    SUDO_PASSWORD = os.getenv('SUDO_PASSWORD')\n",
    "    \n",
    "    bash_command = \"echo {sudo_password} | sudo -S {command}\".format(sudo_password = SUDO_PASSWORD, command = bash_command)\n",
    "    \n",
    "!{bash_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ad9053-eeac-412e-ad65-521c235f74f4",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49c0ea0-1f3a-4685-99db-9340ea0b1f41",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ba5b8e-6097-4baf-82a6-f0f80c97e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import InputLayer, BatchNormalization, Conv2DTranspose, Dense, Reshape, ReLU, LeakyReLU, Conv2D, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08da3b56-3074-4429-99e5-774ccd1ffca6",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817a6d17-714a-432f-b1d8-f72fdfb14437",
   "metadata": {},
   "source": [
    "## Verificar el uso de GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585d799e-aac2-4bd8-8489-0504fca1c7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Numbers of GPUs availables: {gpus_number}\".format(gpus_number = len(tf.config.list_physical_devices(\"GPU\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9274f27d-50b5-4e34-9a1f-fd614713745b",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edaf955-833f-42d8-9529-967dacda8b27",
   "metadata": {},
   "source": [
    "## Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f42ebb6-215a-445b-a6f6-5d21b6166834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories used for the jupyter notebook\n",
    "DIRECTORY_PATHS = {}\n",
    "\n",
    "# Create the directory paths\n",
    "DIRECTORY_PATHS[\"models\"] = path.join('.', 'models')\n",
    "DIRECTORY_PATHS[\"models_architecture\"] = path.join(DIRECTORY_PATHS[\"models\"], 'architecture')\n",
    "DIRECTORY_PATHS[\"models_results\"] = path.join(DIRECTORY_PATHS[\"models\"], 'results')\n",
    "\n",
    "MODEL_ARCHITECTURE_DIRECTORY = DIRECTORY_PATHS[\"models_architecture\"]\n",
    "MODEL_RESULTS_DIRECTORY = DIRECTORY_PATHS[\"models_results\"]\n",
    "\n",
    "# Name of the used models in this jupyter notebook\n",
    "MODEL_NAMES = {\n",
    "    \"generator\": \"Generator\",\n",
    "    \"discriminator\": \"Discriminator\",\n",
    "    \"dcgan\": \"DCGAN\"\n",
    "}\n",
    "\n",
    "# Extension of the architecture files (used by plot_model)\n",
    "EXTENSION = \"pdf\"\n",
    "\n",
    "# Use to map the numeric label to categorical label\n",
    "CATEGORICAL_LABELS = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck'\n",
    "}\n",
    "\n",
    "# Constants used to show images\n",
    "NUM_ROWS = 5\n",
    "NUM_COLUMNS = 5\n",
    "PADDING = .2\n",
    "\n",
    "# Constans used to get random sample\n",
    "SAMPLE_SIZE = NUM_ROWS * NUM_COLUMNS\n",
    "\n",
    "# Constants used to train the DCGAN\n",
    "NUM_EPOCHS = 32\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# BACTH_SIZE = NUM_REAL_DATA_SAMPLE + NUM_FAKE_DATA_SAMPLE\n",
    "NUM_REAL_DATA_SAMPLE = int(BATCH_SIZE / 2)\n",
    "NUM_FAKE_DATA_SAMPLE = NUM_REAL_DATA_SAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd231ab-3d53-412f-badb-acccf1f6adca",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b13f4e-ff12-4c90-8759-38be0bc4b939",
   "metadata": {},
   "source": [
    "## Create directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5117ac1d-dad7-4fdc-b777-83ec53c8002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in DIRECTORY_PATHS.values():\n",
    "    if not path.isdir(directory):\n",
    "        os.mkdir(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a94bf4a-7ba5-4458-bd71-8fbdc190e2c4",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f320dc1-6ec3-4988-a0f9-b135ce6e695c",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba60280e-c4a4-4755-94ae-4d830f238c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(unnormalized_image):\n",
    "    return (unnormalized_image / 127.5) - 1.0\n",
    "\n",
    "def unnormalize_image(normalized_image):\n",
    "    return (127.5 * (1.0 + normalized_image)).astype(int)\n",
    "    \n",
    "def get_model_architecture_file(base_path, file_name, extension):\n",
    "    full_file_name = \"{file_name}.{extension}\".format(file_name = file_name, extension = extension)\n",
    "    return path.join(base_path, full_file_name)\n",
    "\n",
    "def get_random_sample(images, labels, sample_size):\n",
    "    len_images = len(images)\n",
    "    len_labels = len(labels)\n",
    "    if len_images == len_labels:\n",
    "        sample_indices = np.random.permutation(len_images)\n",
    "        sample_indices = sample_indices[:sample_size]\n",
    "        return images[sample_indices], labels[sample_indices]\n",
    "\n",
    "def get_categorical_labels(labels, categorical_labels):\n",
    "    labels = labels.copy().flatten()\n",
    "    if isinstance(categorical_labels, dict):\n",
    "        return [categorical_labels[label] for label in labels]\n",
    "    \n",
    "def get_images(images, labels=None, num_rows=1, num_columns=1, padding=.2, title = None):\n",
    "    fig, ax = plt.subplots(num_rows, num_columns)\n",
    "    fig.tight_layout(pad=padding)\n",
    "    \n",
    "    subplots = ax.flatten() if isinstance(ax, np.ndarray) else [ax]\n",
    "    num_subplots = len(subplots)\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title, y = 1.1)\n",
    "    \n",
    "    for i in range(num_subplots):\n",
    "        subplot = subplots[i]\n",
    "        image = images[i]\n",
    "        \n",
    "        subplot.axis(\"off\")\n",
    "        subplot.imshow(images[i])\n",
    "        \n",
    "        if labels:\n",
    "            label = labels[i]\n",
    "            subplot.set_title(labels[i])\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd97122-8e06-4365-9773-1ccaa359696a",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef68a57-a740-4775-8899-ce27a7b19dbf",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c94a5e-a138-4e17-818a-0bdd4b740c41",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aefb233-cecc-48e6-939a-eb1e7d50ad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2880ca-fc43-43a3-bcda-c52ad5d36e26",
   "metadata": {},
   "source": [
    "### A. Train data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848da20c-9f27-4c56-8096-6f8ace06f3a9",
   "metadata": {},
   "source": [
    "#### Obtain data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dfafa6-4cae-4e3e-b7b6-8eea69cfa1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_x_train, sample_y_train = get_random_sample(x_train, y_train, SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9722b432-cc33-4acf-a1b1-ffbc109085c2",
   "metadata": {},
   "source": [
    "#### Obtain categorical labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b2287b-515e-4f46-8ed7-fe807743ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_categorical_y_train = get_categorical_labels(sample_y_train, CATEGORICAL_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dbb66f-7b16-40ec-9bb9-45dce2067005",
   "metadata": {},
   "source": [
    "#### Show images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef103e0c-fdf0-433e-9a05-776f02d14cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_images(sample_x_train, sample_categorical_y_train, num_rows=NUM_ROWS, num_columns = NUM_COLUMNS, padding = PADDING, title=\"Images from train dataset\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75cb05b-913b-42c5-86d8-5035bf4a4ed1",
   "metadata": {},
   "source": [
    "### B. Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a92d13e-b618-469a-8338-aee421665fa9",
   "metadata": {},
   "source": [
    "#### Obtain data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392b0381-da5d-4eef-a2d5-9779f8086805",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_x_test, sample_y_test = get_random_sample(x_test, y_test, SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1940b8-f930-4be2-9e12-17343cca033c",
   "metadata": {},
   "source": [
    "#### Obtain categorical labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979f0aa4-d23a-44c1-be27-06cce001730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_categorical_y_test = get_categorical_labels(sample_y_test, CATEGORICAL_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccb166f-8d73-4fe9-bdc8-73110cc05491",
   "metadata": {},
   "source": [
    "#### Show images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a75408-5b18-4ca4-8fc8-0a6d4c49a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_images(sample_x_test, sample_categorical_y_test, num_rows = NUM_ROWS, num_columns = NUM_COLUMNS, padding = PADDING, title=\"Images from test dataset\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bfec53-a924-4278-b68f-abbea3f147b4",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9231b1fd-1a70-4e57-b6ce-95ce9f62c320",
   "metadata": {},
   "source": [
    "## Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca770690-55cc-4f55-8d40-4e0e320b41d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(input_shape):\n",
    "    generator = Sequential()\n",
    "\n",
    "    generator.add(InputLayer(shape = input_shape))\n",
    "    generator.add(Dense(4 * 4 * 1024))\n",
    "    generator.add(ReLU())\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(Reshape((4, 4, 1024)))\n",
    "\n",
    "    generator.add(Conv2DTranspose(256, kernel_size = 3, strides = 2, padding = \"same\"))\n",
    "    generator.add(ReLU())\n",
    "    generator.add(BatchNormalization())\n",
    "\n",
    "    generator.add(Conv2DTranspose(128, kernel_size = 3, strides = 2, padding = \"same\"))\n",
    "    generator.add(ReLU())\n",
    "    generator.add(BatchNormalization())\n",
    "\n",
    "    generator.add(Conv2DTranspose(3, kernel_size = 3, strides = 2, padding = \"same\", activation=\"tanh\"))\n",
    "\n",
    "    generator.compile(run_eagerly = True)\n",
    "    \n",
    "    generator.summary()\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58120b8c-e881-4078-b71a-eabe42076746",
   "metadata": {},
   "source": [
    "### Obtain the path to save the architecture file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36858455-5291-4e35-a102-0dc796a52290",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATOR_MODEL_ARCHITECTURE_FILE = get_model_architecture_file(MODEL_ARCHITECTURE_DIRECTORY, MODEL_NAMES[\"generator\"], EXTENSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c927dc8c-d80a-4306-9d0f-8a9b8073914e",
   "metadata": {},
   "source": [
    "### Build generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96fd205-ef84-45d5-a650-4a9f2c665a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_input_shape = (100,)\n",
    "\n",
    "generator = build_generator(generator_input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb1ce37-c349-41dc-97a3-ad1ff2b8b4e5",
   "metadata": {},
   "source": [
    "### Save the plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61561001-297e-4503-ba4f-a577d57b5bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(generator, to_file = GENERATOR_MODEL_ARCHITECTURE_FILE, show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dde23ef-166c-4ca1-9934-57aa01157282",
   "metadata": {},
   "source": [
    "### Create random input to generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a9d52-9133-4aeb-8f4f-9996fad836cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_input = np.random.rand(NUM_ROWS * NUM_COLUMNS, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c55575e-9613-4aab-ad06-c32d49e44fed",
   "metadata": {},
   "source": [
    "### Print shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c74810-c495-4f64-967b-11bebf04afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41da114-8b99-4a57-90f9-e643712f54f9",
   "metadata": {},
   "source": [
    "### Use the generator to create new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba23a1-45e7-4b11-b121-2199ae0d9261",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [unnormalize_image(normalized_image) for normalized_image in generator.predict(random_input)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c7244-b1ce-42a9-9612-ded4dcd2caac",
   "metadata": {},
   "source": [
    "### Show the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d18c8f-c27b-4440-83cd-f743e1711a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_images(result, num_rows = NUM_ROWS, num_columns = NUM_COLUMNS, padding = PADDING, title = \"Images generated by generator\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fb1b0a-5a4e-4693-8802-a803700ec530",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135480b2-dd08-46be-9de1-04d0a7b4a7a1",
   "metadata": {},
   "source": [
    "## Discriminator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa88b54-fe4c-47b2-9a3e-601dee19d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(input_shape):\n",
    "    discriminator = Sequential()\n",
    "\n",
    "    discriminator.add(Conv2D(128, input_shape = input_shape, kernel_size = 3, strides = 2, padding = \"same\"))\n",
    "    discriminator.add(LeakyReLU())\n",
    "    discriminator.add(BatchNormalization())\n",
    "\n",
    "    discriminator.add(Conv2D(256, kernel_size = 3, strides = 2, padding = \"same\"))\n",
    "    discriminator.add(LeakyReLU())\n",
    "    discriminator.add(BatchNormalization())\n",
    "\n",
    "    discriminator.add(Conv2D(1024, kernel_size = 3, strides = 2, padding = \"same\"))\n",
    "    discriminator.add(LeakyReLU())\n",
    "    discriminator.add(BatchNormalization())\n",
    "    \n",
    "    discriminator.add(Flatten())\n",
    "    discriminator.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    optimizer = Adam(learning_rate = 0.01)\n",
    "\n",
    "    discriminator.compile(optimizer = optimizer, loss = \"binary_crossentropy\", metrics = [\"accuracy\"], run_eagerly = True)\n",
    "\n",
    "    discriminator.summary()\n",
    "\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0678d7-e285-4ad0-8e49-12dd2995ea9c",
   "metadata": {},
   "source": [
    "### Obtain the path to save the architecture file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a82ed56-375e-4bb4-a68f-c5d361dbcbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISCRIMINATOR_MODEL_ARCHITECTURE_FILE = get_model_architecture_file(MODEL_ARCHITECTURE_DIRECTORY, MODEL_NAMES[\"discriminator\"], EXTENSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44ff645-8797-4d09-86f2-7a86646bde42",
   "metadata": {},
   "source": [
    "### Build discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124e8c1b-9342-467c-8daa-90a1b276315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_input_shape = (32, 32, 3, )\n",
    "\n",
    "discriminator = build_discriminator(discriminator_input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d71fd3d-817d-4d44-b2e2-be8e2a9e9d21",
   "metadata": {},
   "source": [
    "### Save the plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafcbdfb-dd28-43c6-a397-8a016b5f20cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(discriminator, to_file = DISCRIMINATOR_MODEL_ARCHITECTURE_FILE, show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25036ec4-1e13-4964-b681-e3f1a0f19ef2",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361412ba-7b4f-4b3d-a591-d8ea2aa7aeb3",
   "metadata": {},
   "source": [
    "## DCGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab26bfd-4135-4a21-a455-118f4af7d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dcgan(generator, discriminator, input_shape = None):\n",
    "    # The discriminator's weights are not trainnable when the dcgan is trained.\n",
    "    discriminator.trainnable = False\n",
    "\n",
    "    generator.name = \"Generator\"\n",
    "    discriminator.name = \"Discriminator\"\n",
    "    \n",
    "    dcgan = Sequential()\n",
    "\n",
    "    dcgan.add(InputLayer(shape = input_shape))  \n",
    "    dcgan.add(generator)\n",
    "    dcgan.add(discriminator)\n",
    "\n",
    "    optimizer = Adam(learning_rate = 0.01)\n",
    "\n",
    "    dcgan.compile(optimizer = optimizer, loss = \"binary_crossentropy\", metrics = [\"accuracy\"], run_eagerly = True)\n",
    "\n",
    "    dcgan.summary()\n",
    "    \n",
    "    return dcgan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8709f8c1-9a48-4f01-8dce-f930bd8d2fb9",
   "metadata": {},
   "source": [
    "### Obtain the path to save the architecture file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c31d86-411a-4b26-9e5e-b82565ee9482",
   "metadata": {},
   "outputs": [],
   "source": [
    "DCGAN_MODEL_ARCHITECTURE_FILE = get_model_architecture_file(MODEL_ARCHITECTURE_DIRECTORY, MODEL_NAMES[\"dcgan\"], EXTENSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b077c22-5f92-462e-a76c-90ad7a4b5d51",
   "metadata": {},
   "source": [
    "### Build DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4925692-c9f0-4c75-a350-ed51dbae3580",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan = build_dcgan(generator, discriminator, input_shape = generator_input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99901b76-f328-43c8-affa-ad29dc24c8b8",
   "metadata": {},
   "source": [
    "### Save the plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7fcc45-9cb5-4e15-992c-c26a2a64908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(dcgan, to_file = DCGAN_MODEL_ARCHITECTURE_FILE, show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ae0ee3-1b94-4306-adf7-02c99f006446",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913412c1-040a-404e-9047-68cf9d6b7560",
   "metadata": {},
   "source": [
    "## Train DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6936e2ad-eee2-4355-9e1f-b0c38febd5e7",
   "metadata": {},
   "source": [
    "### Define functions used to train dcgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "382b85ff-f6f2-4dba-81d2-34e90246fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_image_batch(images, batch_size = 32):\n",
    "    images = images.copy()\n",
    "\n",
    "    # Shuffle the images\n",
    "    np.random.shuffle(images)\n",
    "\n",
    "    # Obtain the number of complete batches\n",
    "    num_batch = int(len(images) / batch_size)\n",
    "    # Obtain the number of total images used to generate complete batches\n",
    "    num_images = num_batch * batch_size\n",
    "\n",
    "    # Obtain the images \n",
    "    images = images[ : num_images]\n",
    "\n",
    "    # Preprocess the image\n",
    "    images = np.array(list(map(normalize_image, images)))\n",
    "\n",
    "    for i in range(num_batch):\n",
    "        yield images[i * batch_size : (i + 1) * batch_size]\n",
    "\n",
    "def get_discriminator_sample(fake_data, fake_labels, real_data, real_labels):\n",
    "    train_data = np.concatenate([fake_data, real_data], axis = 0)\n",
    "    train_labels = np.concatenate([fake_labels, real_labels], axis = 0)\n",
    "\n",
    "    return train_data, train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8172150c-d446-4532-889f-a85efbaac659",
   "metadata": {},
   "source": [
    "### Train DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b78460-aa7b-49fb-819e-27ad71c57563",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, NUM_EPOCHS + 1): \n",
    "    for real_images in get_real_image_batch(x_train, batch_size = NUM_REAL_DATA_SAMPLE):\n",
    "        # ----- Train discriminator -----\n",
    "        \n",
    "        # Generate noise by the generator to create a new images\n",
    "        noise = np.random.rand(NUM_FAKE_DATA_SAMPLE, 100)\n",
    "\n",
    "        # Generate the fake images and fake labels\n",
    "        fake_images = generator.predict_on_batch(noise).astype(np.float32)\n",
    "        fake_labels = np.zeros((NUM_FAKE_DATA_SAMPLE, 1), dtype = np.float32)\n",
    "        \n",
    "        # Generate the real labels\n",
    "        real_labels = np.ones((NUM_REAL_DATA_SAMPLE, 1)).astype(np.float32)\n",
    "        \n",
    "        # Combine the fake and real images and fake and real labels\n",
    "        discriminator_train_data, discriminator_train_labels = get_discriminator_sample(fake_images, fake_labels, real_images, real_labels)\n",
    "        \n",
    "        # First train the discriminator\n",
    "        discriminator.train_on_batch(discriminator_train_data, discriminator_train_labels)\n",
    "        \n",
    "        # ----- Train the dcgan -----\n",
    "    \n",
    "        # Generate new noise\n",
    "        dcgan_train_data = np.random.rand(BATCH_SIZE, 100).astype(np.float32)\n",
    "        \n",
    "        # The label is changed to deceive to discriminator, equivalent to maximize log(D(G(z))). See https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "        dcgan_train_labels = np.ones((BATCH_SIZE, 1)).astype(np.float32)\n",
    "    \n",
    "        # Train dcgan\n",
    "        dcgan.train_on_batch(dcgan_train_data, dcgan_train_labels)\n",
    "\n",
    "    # ----- Show results -----\n",
    "        \n",
    "    # Generate new noise\n",
    "    noise = np.random.rand(NUM_ROWS * NUM_COLUMNS, 100)\n",
    "    \n",
    "    new_images = np.array([unnormalize_image(normalized_image) for normalized_image in generator.predict_on_batch(noise)])\n",
    "    \n",
    "    # Save new images\n",
    "    filename = path.join(MODEL_RESULTS_DIRECTORY, \"result_in_epoch{num_epoch}.{extension}\".format(num_epoch = epoch, extension = EXTENSION))\n",
    "    \n",
    "    plot_title = \"Images generated by generator in the epochs: {epoch}\".format(epoch = epoch)\n",
    "    plot_images = get_images(new_images, num_rows = NUM_ROWS, num_columns = NUM_COLUMNS, padding = PADDING, title = plot_title)\n",
    "\n",
    "    plot_images.savefig(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
